{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSC 180 Intelligent Systems \n",
    "\n",
    "#### William Lorence, Ajaydeep Singh, Romin Akoliya, Abdurraziq Paikur\n",
    "\n",
    "#### California State University, Sacramento\n",
    "\n",
    "# Final Project: NBA Outcome Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nba_api.stats.static import teams, players\n",
    "from nba_api.stats.endpoints import leaguegamefinder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Team and Player Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SEASON_ID     TEAM_ID TEAM_ABBREVIATION      TEAM_NAME     GAME_ID  \\\n",
      "0     22024  1610612737               ATL  Atlanta Hawks  0022400239   \n",
      "1     22024  1610612737               ATL  Atlanta Hawks  0022400012   \n",
      "2     22024  1610612737               ATL  Atlanta Hawks  0022400001   \n",
      "3     22024  1610612737               ATL  Atlanta Hawks  0022400198   \n",
      "4     22024  1610612737               ATL  Atlanta Hawks  0022400185   \n",
      "\n",
      "    GAME_DATE      MATCHUP    WL  MIN  PTS  ...  FT_PCT  OREB  DREB  REB  AST  \\\n",
      "0  2024-11-17    ATL @ POR  None  228  111  ...   0.840    16    31   47   30   \n",
      "1  2024-11-15  ATL vs. WAS     W  240  129  ...   0.833    15    40   55   28   \n",
      "2  2024-11-12    ATL @ BOS     W  240  117  ...   0.538    19    25   44   35   \n",
      "3  2024-11-09  ATL vs. CHI     L  240  113  ...   0.733    10    29   39   31   \n",
      "4  2024-11-08    ATL @ DET     L  240  121  ...   0.783    15    29   44   30   \n",
      "\n",
      "    STL  BLK  TOV  PF  PLUS_MINUS  \n",
      "0  10.0    7   25  19       -10.2  \n",
      "1  10.0   10   16  17        12.0  \n",
      "2  16.0    2   16  17         1.0  \n",
      "3   8.0    5   13  19       -12.0  \n",
      "4  12.0    7   17  21        -1.0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "from nba_api.stats.endpoints import leaguegamefinder\n",
    "\n",
    "# Example: Get all games played by the Atlanta Hawks\n",
    "gamefinder = leaguegamefinder.LeagueGameFinder(team_id_nullable=1610612737)\n",
    "games = gamefinder.get_data_frames()[0]  # Fetch the data as a DataFrame\n",
    "\n",
    "# Display the first few rows\n",
    "print(games.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter and Format Data: Extract key information such as:\n",
    "\n",
    "### Season\n",
    "### Wins and losses\n",
    "### Opponent teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SEASON      TEAM_NAME   GAME_DATE      MATCHUP    WIN\n",
      "0    2202  Atlanta Hawks  2024-11-17    ATL @ POR  False\n",
      "1    2202  Atlanta Hawks  2024-11-15  ATL vs. WAS   True\n",
      "2    2202  Atlanta Hawks  2024-11-12    ATL @ BOS   True\n",
      "3    2202  Atlanta Hawks  2024-11-09  ATL vs. CHI  False\n",
      "4    2202  Atlanta Hawks  2024-11-08    ATL @ DET  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8508\\3731708797.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  recent_games['WIN'] = recent_games['WL'] == 'W'\n"
     ]
    }
   ],
   "source": [
    "# Filter for games from the last 20 years\n",
    "games['SEASON'] = games['SEASON_ID'].str[:4].astype(int)\n",
    "recent_games = games[games['SEASON'] >= 2004]\n",
    "\n",
    "# Create a simple win/loss indicator\n",
    "recent_games['WIN'] = recent_games['WL'] == 'W'\n",
    "\n",
    "# Display processed data\n",
    "print(recent_games[['SEASON', 'TEAM_NAME', 'GAME_DATE', 'MATCHUP', 'WIN']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Player Career Averages: Use the playercareerstats endpoint to get data for individual players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SEASON_ID   PTS  AST  REB\n",
      "17   2020-21  1126  350  346\n",
      "18   2021-22  1695  349  459\n",
      "19   2022-23  1590  375  457\n",
      "20   2023-24  1822  589  518\n",
      "21   2024-25   303  120  112\n"
     ]
    }
   ],
   "source": [
    "from nba_api.stats.endpoints import playercareerstats\n",
    "\n",
    "# Example: Fetch career stats for a specific player (LeBron James)\n",
    "player_id = 2544  # LeBron James' ID\n",
    "career = playercareerstats.PlayerCareerStats(player_id=player_id)\n",
    "career_data = career.get_data_frames()[0]\n",
    "\n",
    "# Display the career averages\n",
    "print(career_data[['SEASON_ID', 'PTS', 'AST', 'REB']].tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Data: Save the data into CSV files for easier use later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_games.to_csv('team_records.csv', index=False)\n",
    "career_data.to_csv('player_career_averages.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Combining Datasets\n",
    "### Load the Datasets: Import the CSV files into pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team Data:\n",
      "   SEASON_ID     TEAM_ID TEAM_ABBREVIATION      TEAM_NAME   GAME_ID  \\\n",
      "0      22024  1610612737               ATL  Atlanta Hawks  22400239   \n",
      "1      22024  1610612737               ATL  Atlanta Hawks  22400012   \n",
      "2      22024  1610612737               ATL  Atlanta Hawks  22400001   \n",
      "3      22024  1610612737               ATL  Atlanta Hawks  22400198   \n",
      "4      22024  1610612737               ATL  Atlanta Hawks  22400185   \n",
      "\n",
      "    GAME_DATE      MATCHUP   WL  MIN  PTS  ...  DREB  REB  AST   STL  BLK  \\\n",
      "0  2024-11-17    ATL @ POR  NaN  228  111  ...    31   47   30  10.0    7   \n",
      "1  2024-11-15  ATL vs. WAS    W  240  129  ...    40   55   28  10.0   10   \n",
      "2  2024-11-12    ATL @ BOS    W  240  117  ...    25   44   35  16.0    2   \n",
      "3  2024-11-09  ATL vs. CHI    L  240  113  ...    29   39   31   8.0    5   \n",
      "4  2024-11-08    ATL @ DET    L  240  121  ...    29   44   30  12.0    7   \n",
      "\n",
      "   TOV  PF  PLUS_MINUS  SEASON    WIN  \n",
      "0   25  19       -10.2    2202  False  \n",
      "1   16  17        12.0    2202   True  \n",
      "2   16  17         1.0    2202   True  \n",
      "3   13  19       -12.0    2202  False  \n",
      "4   17  21        -1.0    2202  False  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Player Data:\n",
      "   PLAYER_ID SEASON_ID  LEAGUE_ID     TEAM_ID TEAM_ABBREVIATION  PLAYER_AGE  \\\n",
      "0       2544   2003-04          0  1610612739               CLE        19.0   \n",
      "1       2544   2004-05          0  1610612739               CLE        20.0   \n",
      "2       2544   2005-06          0  1610612739               CLE        21.0   \n",
      "3       2544   2006-07          0  1610612739               CLE        22.0   \n",
      "4       2544   2007-08          0  1610612739               CLE        23.0   \n",
      "\n",
      "   GP  GS     MIN  FGM  ...  FT_PCT  OREB  DREB  REB  AST  STL  BLK  TOV   PF  \\\n",
      "0  79  79  3120.0  622  ...   0.754    99   333  432  465  130   58  273  149   \n",
      "1  80  80  3388.0  795  ...   0.750   111   477  588  577  177   52  262  146   \n",
      "2  79  79  3361.0  875  ...   0.738    75   481  556  521  123   66  260  181   \n",
      "3  78  78  3190.0  772  ...   0.698    83   443  526  470  125   55  250  171   \n",
      "4  75  74  3027.0  794  ...   0.712   133   459  592  539  138   81  255  165   \n",
      "\n",
      "    PTS  \n",
      "0  1654  \n",
      "1  2175  \n",
      "2  2478  \n",
      "3  2132  \n",
      "4  2250  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "team_data = pd.read_csv('team_records.csv')\n",
    "player_data = pd.read_csv('player_career_averages.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Team Data:\")\n",
    "print(team_data.head())\n",
    "print(\"\\nPlayer Data:\")\n",
    "print(player_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Team Data:\n",
    "\n",
    "#### Extract relevant columns (e.g., season, team name, win/loss).\n",
    "#### Encode the target variable (win/loss) as 1 for win and 0 for loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SEASON      TEAM_NAME   GAME_DATE      MATCHUP  WIN\n",
      "0    2202  Atlanta Hawks  2024-11-17    ATL @ POR    0\n",
      "1    2202  Atlanta Hawks  2024-11-15  ATL vs. WAS    1\n",
      "2    2202  Atlanta Hawks  2024-11-12    ATL @ BOS    1\n",
      "3    2202  Atlanta Hawks  2024-11-09  ATL vs. CHI    0\n",
      "4    2202  Atlanta Hawks  2024-11-08    ATL @ DET    0\n"
     ]
    }
   ],
   "source": [
    "team_data['WIN'] = team_data['WIN'].astype(int)  # Convert Boolean to integer\n",
    "team_data_processed = team_data[['SEASON', 'TEAM_NAME', 'GAME_DATE', 'MATCHUP', 'WIN']]\n",
    "print(team_data_processed.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Player Data:\n",
    "\n",
    "#### Filter career averages for relevant stats (e.g., points, assists, rebounds).\n",
    "#### Create a dictionary of player stats grouped by season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SEASON_ID  PLAYER_ID   PTS  AST  REB\n",
      "0       2003       2544  1654  465  432\n",
      "1       2004       2544  2175  577  588\n",
      "2       2005       2544  2478  521  556\n",
      "3       2006       2544  2132  470  526\n",
      "4       2007       2544  2250  539  592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8508\\2326349354.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  player_data_filtered['SEASON_ID'] = player_data_filtered['SEASON_ID'].str[:4].astype(int)  # Extract season year\n"
     ]
    }
   ],
   "source": [
    "player_data_filtered = player_data[['SEASON_ID', 'PLAYER_ID', 'PTS', 'AST', 'REB']]\n",
    "player_data_filtered['SEASON_ID'] = player_data_filtered['SEASON_ID'].str[:4].astype(int)  # Extract season year\n",
    "print(player_data_filtered.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SEASON      TEAM_NAME   GAME_DATE      MATCHUP  WIN  TEAM_PTS_AVG  \\\n",
      "0    2202  Atlanta Hawks  2024-11-17    ATL @ POR    0           NaN   \n",
      "1    2202  Atlanta Hawks  2024-11-15  ATL vs. WAS    1           NaN   \n",
      "2    2202  Atlanta Hawks  2024-11-12    ATL @ BOS    1           NaN   \n",
      "3    2202  Atlanta Hawks  2024-11-09  ATL vs. CHI    0           NaN   \n",
      "4    2202  Atlanta Hawks  2024-11-08    ATL @ DET    0           NaN   \n",
      "\n",
      "   TEAM_AST_AVG  TEAM_REB_AVG  \n",
      "0           NaN           NaN  \n",
      "1           NaN           NaN  \n",
      "2           NaN           NaN  \n",
      "3           NaN           NaN  \n",
      "4           NaN           NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8508\\110984493.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  team_data_processed[['TEAM_PTS_AVG', 'TEAM_AST_AVG', 'TEAM_REB_AVG']] = team_data_processed.apply(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8508\\110984493.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  team_data_processed[['TEAM_PTS_AVG', 'TEAM_AST_AVG', 'TEAM_REB_AVG']] = team_data_processed.apply(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8508\\110984493.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  team_data_processed[['TEAM_PTS_AVG', 'TEAM_AST_AVG', 'TEAM_REB_AVG']] = team_data_processed.apply(\n"
     ]
    }
   ],
   "source": [
    "def calculate_team_stats(season, team_name, player_data):\n",
    "    # Filter players for the given team and season\n",
    "    players_on_team = player_data[player_data['SEASON_ID'] == season]\n",
    "    \n",
    "    # Calculate averages for relevant stats\n",
    "    avg_pts = players_on_team['PTS'].mean()\n",
    "    avg_ast = players_on_team['AST'].mean()\n",
    "    avg_reb = players_on_team['REB'].mean()\n",
    "    \n",
    "    return avg_pts, avg_ast, avg_reb\n",
    "\n",
    "# Add separate columns for each stat\n",
    "team_data_processed[['TEAM_PTS_AVG', 'TEAM_AST_AVG', 'TEAM_REB_AVG']] = team_data_processed.apply(\n",
    "    lambda row: pd.Series(calculate_team_stats(row['SEASON'], row['TEAM_NAME'], player_data_filtered)),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(team_data_processed.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_data_processed.to_csv('combined_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.ipynb_checkpoints', 'combined_dataset.csv', 'finalproject.ipynb', 'player_career_averages.csv', 'team_records.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (2518, 3)\n",
      "Test features shape: (1080, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('combined_dataset.csv')\n",
    "\n",
    "# Select features and target\n",
    "X = data[['TEAM_PTS_AVG', 'TEAM_AST_AVG', 'TEAM_REB_AVG']]  # Use more features if available\n",
    "y = data['WIN']  # Target variable\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Display the shape of training and test sets\n",
    "print(\"Training features shape:\", X_train.shape)\n",
    "print(\"Test features shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Build the Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\tf_env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,369</span> (9.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,369\u001b[0m (9.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,369</span> (9.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,369\u001b[0m (9.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # Input layer\n",
    "    Dense(32, activation='relu'),  # Hidden layer\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5227 - loss: 0.6931 - val_accuracy: 0.5456 - val_loss: 0.6926\n",
      "Epoch 2/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5002 - loss: 0.6932 - val_accuracy: 0.5456 - val_loss: 0.6925\n",
      "Epoch 3/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4998 - loss: 0.6932 - val_accuracy: 0.5456 - val_loss: 0.6922\n",
      "Epoch 4/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5112 - loss: 0.6930 - val_accuracy: 0.5456 - val_loss: 0.6920\n",
      "Epoch 5/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5109 - loss: 0.6930 - val_accuracy: 0.5456 - val_loss: 0.6920\n",
      "Epoch 6/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5072 - loss: 0.6931 - val_accuracy: 0.5456 - val_loss: 0.6920\n",
      "Epoch 7/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5082 - loss: 0.6930 - val_accuracy: 0.5456 - val_loss: 0.6918\n",
      "Epoch 8/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5118 - loss: 0.6929 - val_accuracy: 0.5456 - val_loss: 0.6918\n",
      "Epoch 9/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5248 - loss: 0.6925 - val_accuracy: 0.5456 - val_loss: 0.6916\n",
      "Epoch 10/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5160 - loss: 0.6928 - val_accuracy: 0.5456 - val_loss: 0.6916\n",
      "Epoch 11/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4964 - loss: 0.6934 - val_accuracy: 0.5456 - val_loss: 0.6917\n",
      "Epoch 12/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5032 - loss: 0.6932 - val_accuracy: 0.5456 - val_loss: 0.6917\n",
      "Epoch 13/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5236 - loss: 0.6925 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 14/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4978 - loss: 0.6935 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 15/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5250 - loss: 0.6924 - val_accuracy: 0.5456 - val_loss: 0.6916\n",
      "Epoch 16/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5127 - loss: 0.6929 - val_accuracy: 0.5456 - val_loss: 0.6916\n",
      "Epoch 17/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4965 - loss: 0.6935 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 18/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5179 - loss: 0.6926 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 19/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6928 - val_accuracy: 0.5456 - val_loss: 0.6914\n",
      "Epoch 20/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5168 - loss: 0.6927 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 21/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4968 - loss: 0.6935 - val_accuracy: 0.5456 - val_loss: 0.6916\n",
      "Epoch 22/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5290 - loss: 0.6922 - val_accuracy: 0.5456 - val_loss: 0.6914\n",
      "Epoch 23/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5161 - loss: 0.6927 - val_accuracy: 0.5456 - val_loss: 0.6916\n",
      "Epoch 24/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5212 - loss: 0.6925 - val_accuracy: 0.5456 - val_loss: 0.6915\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# EarlyStopping to monitor validation loss\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,  # 20% of training data for validation\n",
    "    epochs=50,             # Maximum number of epochs\n",
    "    batch_size=32,         # Number of samples per gradient update\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1              # Display training progress\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.5073 - loss: 0.6931\n",
      "Test Loss: 0.6937479972839355\n",
      "Test Accuracy: 0.49166667461395264\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning and Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Confusion Matrix:\n",
      "[[531   0]\n",
      " [549   0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.66       531\n",
      "           1       0.00      0.00      0.00       549\n",
      "\n",
      "    accuracy                           0.49      1080\n",
      "   macro avg       0.25      0.50      0.33      1080\n",
      "weighted avg       0.24      0.49      0.32      1080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\tf_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\tf_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\tf_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Make predictions\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Model Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8508\\2731300222.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  team_data_processed[['OPP_PTS_AVG', 'OPP_AST_AVG', 'OPP_REB_AVG']] = team_data_processed.apply(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8508\\2731300222.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  team_data_processed[['OPP_PTS_AVG', 'OPP_AST_AVG', 'OPP_REB_AVG']] = team_data_processed.apply(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8508\\2731300222.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  team_data_processed[['OPP_PTS_AVG', 'OPP_AST_AVG', 'OPP_REB_AVG']] = team_data_processed.apply(\n"
     ]
    }
   ],
   "source": [
    "# Merge opponent stats into the dataset\n",
    "def calculate_opponent_stats(row, player_data):\n",
    "    # Extract season and opponent team name from the row\n",
    "    season = row['SEASON']\n",
    "    opponent = row['MATCHUP'].split(' ')[-1]\n",
    "    \n",
    "    # Filter player data for the opponent team and season\n",
    "    opponent_players = player_data[player_data['SEASON_ID'] == season]\n",
    "    avg_pts = opponent_players['PTS'].mean()\n",
    "    avg_ast = opponent_players['AST'].mean()\n",
    "    avg_reb = opponent_players['REB'].mean()\n",
    "    \n",
    "    return avg_pts, avg_ast, avg_reb\n",
    "\n",
    "# Add opponent stats\n",
    "team_data_processed[['OPP_PTS_AVG', 'OPP_AST_AVG', 'OPP_REB_AVG']] = team_data_processed.apply(\n",
    "    lambda row: pd.Series(calculate_opponent_stats(row, player_data_filtered)),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Save the updated dataset\n",
    "team_data_processed.to_csv('enhanced_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\tf_env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4991 - loss: 0.6931 - val_accuracy: 0.5456 - val_loss: 0.6928\n",
      "Epoch 2/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5064 - loss: 0.6931 - val_accuracy: 0.5456 - val_loss: 0.6927\n",
      "Epoch 3/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5040 - loss: 0.6931 - val_accuracy: 0.5456 - val_loss: 0.6924\n",
      "Epoch 4/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4930 - loss: 0.6933 - val_accuracy: 0.5456 - val_loss: 0.6922\n",
      "Epoch 5/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5186 - loss: 0.6928 - val_accuracy: 0.5456 - val_loss: 0.6920\n",
      "Epoch 6/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5069 - loss: 0.6931 - val_accuracy: 0.5456 - val_loss: 0.6920\n",
      "Epoch 7/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5137 - loss: 0.6929 - val_accuracy: 0.5456 - val_loss: 0.6918\n",
      "Epoch 8/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5335 - loss: 0.6922 - val_accuracy: 0.5456 - val_loss: 0.6917\n",
      "Epoch 9/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4825 - loss: 0.6939 - val_accuracy: 0.5456 - val_loss: 0.6919\n",
      "Epoch 10/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4892 - loss: 0.6936 - val_accuracy: 0.5456 - val_loss: 0.6917\n",
      "Epoch 11/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5110 - loss: 0.6929 - val_accuracy: 0.5456 - val_loss: 0.6917\n",
      "Epoch 12/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5073 - loss: 0.6931 - val_accuracy: 0.5456 - val_loss: 0.6916\n",
      "Epoch 13/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5205 - loss: 0.6926 - val_accuracy: 0.5456 - val_loss: 0.6916\n",
      "Epoch 14/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5217 - loss: 0.6925 - val_accuracy: 0.5456 - val_loss: 0.6916\n",
      "Epoch 15/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4995 - loss: 0.6934 - val_accuracy: 0.5456 - val_loss: 0.6916\n",
      "Epoch 16/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5102 - loss: 0.6929 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 17/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5110 - loss: 0.6929 - val_accuracy: 0.5456 - val_loss: 0.6916\n",
      "Epoch 18/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5018 - loss: 0.6933 - val_accuracy: 0.5456 - val_loss: 0.6916\n",
      "Epoch 19/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5246 - loss: 0.6924 - val_accuracy: 0.5456 - val_loss: 0.6914\n",
      "Epoch 20/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5063 - loss: 0.6931 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 21/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5248 - loss: 0.6923 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 22/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5196 - loss: 0.6926 - val_accuracy: 0.5456 - val_loss: 0.6914\n",
      "Epoch 23/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4945 - loss: 0.6936 - val_accuracy: 0.5456 - val_loss: 0.6916\n",
      "Epoch 24/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5095 - loss: 0.6930 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 25/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5106 - loss: 0.6929 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 26/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4950 - loss: 0.6936 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 27/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5089 - loss: 0.6930 - val_accuracy: 0.5456 - val_loss: 0.6914\n",
      "Epoch 28/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4926 - loss: 0.6937 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 29/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5073 - loss: 0.6931 - val_accuracy: 0.5456 - val_loss: 0.6914\n",
      "Epoch 30/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5084 - loss: 0.6930 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 31/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5197 - loss: 0.6926 - val_accuracy: 0.5456 - val_loss: 0.6914\n",
      "Epoch 32/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5159 - loss: 0.6927 - val_accuracy: 0.5456 - val_loss: 0.6914\n",
      "Epoch 33/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5164 - loss: 0.6927 - val_accuracy: 0.5456 - val_loss: 0.6914\n",
      "Epoch 34/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5072 - loss: 0.6931 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 35/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6924 - val_accuracy: 0.5456 - val_loss: 0.6914\n",
      "Epoch 36/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5206 - loss: 0.6925 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 37/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.6928 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 38/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5229 - loss: 0.6924 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 39/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5284 - loss: 0.6922 - val_accuracy: 0.5456 - val_loss: 0.6914\n",
      "Epoch 40/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5333 - loss: 0.6919 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 41/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5149 - loss: 0.6928 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 42/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5118 - loss: 0.6929 - val_accuracy: 0.5456 - val_loss: 0.6916\n",
      "Epoch 43/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4979 - loss: 0.6934 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 44/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5080 - loss: 0.6930 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 45/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5059 - loss: 0.6931 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 46/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5152 - loss: 0.6927 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 47/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5189 - loss: 0.6926 - val_accuracy: 0.5456 - val_loss: 0.6915\n",
      "Epoch 48/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4993 - loss: 0.6934 - val_accuracy: 0.5456 - val_loss: 0.6916\n",
      "Epoch 49/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5214 - loss: 0.6925 - val_accuracy: 0.5456 - val_loss: 0.6914\n",
      "Epoch 50/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5053 - loss: 0.6932 - val_accuracy: 0.5456 - val_loss: 0.6914\n"
     ]
    }
   ],
   "source": [
    "# Load the enhanced dataset\n",
    "data = pd.read_csv('enhanced_dataset.csv')\n",
    "\n",
    "# Include opponent stats in features\n",
    "X = data[['TEAM_PTS_AVG', 'TEAM_AST_AVG', 'TEAM_REB_AVG', 'OPP_PTS_AVG', 'OPP_AST_AVG', 'OPP_REB_AVG']]\n",
    "y = data['WIN']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Retrain the model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.5073 - loss: 0.6931\n",
      "Improved Test Loss: 0.6937205195426941\n",
      "Improved Test Accuracy: 0.49166667461395264\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Confusion Matrix:\n",
      "[[531   0]\n",
      " [549   0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.66       531\n",
      "           1       0.00      0.00      0.00       549\n",
      "\n",
      "    accuracy                           0.49      1080\n",
      "   macro avg       0.25      0.50      0.33      1080\n",
      "weighted avg       0.24      0.49      0.32      1080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\tf_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\tf_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\tf_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the improved model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Improved Test Loss: {test_loss}\")\n",
    "print(f\"Improved Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WIN\n",
      "0    1834\n",
      "1    1764\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "print(data['WIN'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Adding a home game indicator\n",
    "data['HOME_GAME'] = data['MATCHUP'].apply(lambda x: 1 if 'vs.' in x else 0)\n",
    "\n",
    "# Example: Adding recent form (requires sorting by game date)\n",
    "data['RECENT_WINS'] = data.groupby('TEAM_NAME')['WIN'].rolling(5).mean().reset_index(0, drop=True)\n",
    "\n",
    "# Drop NaN values generated from rolling averages\n",
    "data.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjust the Model Archtecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\tf_env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [TEAM_PTS_AVG, TEAM_AST_AVG, TEAM_REB_AVG, OPP_PTS_AVG, OPP_AST_AVG, OPP_REB_AVG, HOME_GAME, RECENT_WINS]\n",
      "Index: []\n",
      "Feature Set Shape: (0, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X.head())  # Display the first few rows\n",
    "print(\"Feature Set Shape:\", X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: WIN, dtype: int64)\n",
      "Target Shape: (0,)\n"
     ]
    }
   ],
   "source": [
    "print(y.head())  # Display the first few rows\n",
    "print(\"Target Shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   TEAM_PTS_AVG  0 non-null      float64\n",
      " 1   TEAM_AST_AVG  0 non-null      float64\n",
      " 2   TEAM_REB_AVG  0 non-null      float64\n",
      " 3   OPP_PTS_AVG   0 non-null      float64\n",
      " 4   OPP_AST_AVG   0 non-null      float64\n",
      " 5   OPP_REB_AVG   0 non-null      float64\n",
      " 6   HOME_GAME     0 non-null      int64  \n",
      " 7   RECENT_WINS   0 non-null      float64\n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 0.0 bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data[['TEAM_PTS_AVG', 'TEAM_AST_AVG', 'TEAM_REB_AVG', 'OPP_PTS_AVG', 'OPP_AST_AVG', 'OPP_REB_AVG', 'HOME_GAME', 'RECENT_WINS']].info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OPP_PTS_AVG  OPP_AST_AVG  OPP_REB_AVG\n",
      "0          NaN          NaN          NaN\n",
      "1          NaN          NaN          NaN\n",
      "2          NaN          NaN          NaN\n",
      "3          NaN          NaN          NaN\n",
      "4          NaN          NaN          NaN\n"
     ]
    }
   ],
   "source": [
    "# Check if opponent stats are being calculated correctly\n",
    "print(team_data_processed[['OPP_PTS_AVG', 'OPP_AST_AVG', 'OPP_REB_AVG']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_opponent_stats(row, player_data):\n",
    "    # Extract season and opponent team name from the row\n",
    "    season = row['SEASON']\n",
    "    opponent = row['MATCHUP'].split(' ')[-1]  # Adjust this based on actual MATCHUP format\n",
    "\n",
    "    # Filter player data for the opponent team and season\n",
    "    opponent_players = player_data[(player_data['SEASON_ID'] == season) & (player_data['TEAM_NAME'] == opponent)]\n",
    "    \n",
    "    if not opponent_players.empty:\n",
    "        # Calculate average stats for the opponent team\n",
    "        avg_pts = opponent_players['PTS'].mean()\n",
    "        avg_ast = opponent_players['AST'].mean()\n",
    "        avg_reb = opponent_players['REB'].mean()\n",
    "    else:\n",
    "        # Default values for missing opponent data\n",
    "        avg_pts = 0\n",
    "        avg_ast = 0\n",
    "        avg_reb = 0\n",
    "    \n",
    "    return avg_pts, avg_ast, avg_reb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
